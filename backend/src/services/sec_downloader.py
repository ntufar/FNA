"""
SECDownloader service for FNA Platform.

Implements automatic downloading of financial reports from SEC.gov EDGAR database
using the official REST API with proper rate limiting and compliance.
"""

import logging
import os
import time
from datetime import datetime, date
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import asyncio

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

from ..core.config import get_settings
from ..core.exceptions import SECAPIError, FileProcessingError, log_performance
from ..models import FinancialReport, ReportType, FileFormat, DownloadSource, ProcessingStatus

logger = logging.getLogger(__name__)


class SECFilingInfo:
    """Container for SEC filing information."""
    
    def __init__(
        self,
        accession_number: str,
        filing_date: str,
        report_type: str,
        report_url: str,
        file_format: str,
        file_size: Optional[int] = None,
        fiscal_period: Optional[str] = None
    ):
        self.accession_number = accession_number
        self.filing_date = filing_date
        self.report_type = report_type
        self.report_url = report_url
        self.file_format = file_format
        self.file_size = file_size
        self.fiscal_period = fiscal_period
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert filing info to dictionary."""
        return {
            'accession_number': self.accession_number,
            'filing_date': self.filing_date,
            'report_type': self.report_type,
            'report_url': self.report_url,
            'file_format': self.file_format,
            'file_size': self.file_size,
            'fiscal_period': self.fiscal_period
        }


class SECDownloader:
    """
    SEC EDGAR database downloader with rate limiting and compliance.
    
    Implements proper SEC.gov API usage guidelines including:
    - 10 requests per second rate limit
    - Required User-Agent header
    - Proper error handling and retries
    - Support for multiple filing types (10-K, 10-Q, 8-K)
    """
    
    def __init__(self):
        """Initialize SEC downloader with proper configuration."""
        self.settings = get_settings()
        self.user_agent = self.settings.sec_user_agent
        self.rate_limit = self.settings.sec_request_rate_limit  # requests per second
        self.base_url = "https://data.sec.gov"
        self.edgar_url = "https://www.sec.gov"
        
        # Rate limiting state
        self.last_request_time = 0.0
        self.min_request_interval = 1.0 / self.rate_limit  # seconds between requests
        
        # Setup HTTP session with retries and proper headers
        self.session = requests.Session()
        
        # Required headers for SEC.gov compliance
        self.session.headers.update({
            'User-Agent': self.user_agent,
            'Accept': 'application/json, text/html, */*',
            'Accept-Encoding': 'gzip, deflate',
            'Host': 'data.sec.gov'
        })
        
        # Setup retry strategy
        retry_strategy = Retry(
            total=3,
            status_forcelist=[429, 500, 502, 503, 504],
            backoff_factor=2,
            respect_retry_after_header=True
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("https://", adapter)
        
        # Create upload directory if it doesn't exist
        self.upload_dir = Path(self.settings.upload_directory)
        self.upload_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"SECDownloader initialized with rate limit: {self.rate_limit} req/sec")
    
    def _enforce_rate_limit(self):
        """Enforce SEC.gov rate limit (10 requests per second)."""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < self.min_request_interval:
            sleep_time = self.min_request_interval - time_since_last
            logger.debug(f"Rate limiting: sleeping {sleep_time:.2f}s")
            time.sleep(sleep_time)
        
        self.last_request_time = time.time()
    
    def _make_sec_request(self, url: str) -> requests.Response:
        """
        Make rate-limited request to SEC API.
        
        Args:
            url: SEC API endpoint URL
            
        Returns:
            requests.Response: API response
            
        Raises:
            SECAPIError: If request fails
        """
        try:
            self._enforce_rate_limit()
            
            logger.debug(f"Making SEC API request: {url}")
            response = self.session.get(url, timeout=30)
            
            if response.status_code == 429:
                # Rate limited - wait and retry once
                logger.warning("SEC API rate limit hit, waiting 60 seconds")
                time.sleep(60)
                self._enforce_rate_limit()
                response = self.session.get(url, timeout=30)
            
            response.raise_for_status()
            return response
            
        except requests.exceptions.RequestException as e:
            raise SECAPIError(f"SEC API request failed: {str(e)}")
    
    def _normalize_ticker(self, ticker: str) -> str:
        """
        Normalize ticker symbol for SEC lookup.
        
        Args:
            ticker: Company ticker symbol
            
        Returns:
            str: Normalized ticker symbol
        """
        return ticker.upper().strip()
    
    def _get_cik_from_ticker(self, ticker: str) -> str:
        """
        Get CIK number from ticker symbol using SEC company tickers API.
        
        Args:
            ticker: Company ticker symbol
            
        Returns:
            str: CIK number with leading zeros
            
        Raises:
            SECAPIError: If ticker not found or API fails
        """
        try:
            ticker = self._normalize_ticker(ticker)
            
            # Use SEC company tickers endpoint
            url = f"{self.base_url}/files/company_tickers.json"
            response = self._make_sec_request(url)
            
            company_data = response.json()
            
            # Search for ticker in the data
            for entry in company_data.values():
                if isinstance(entry, dict) and entry.get('ticker') == ticker:
                    cik = entry.get('cik_str')
                    # Format CIK with leading zeros (10 digits)
                    return f"{cik:010d}" if isinstance(cik, int) else str(cik).zfill(10)
            
            raise SECAPIError(f"Ticker '{ticker}' not found in SEC database")
            
        except Exception as e:
            if isinstance(e, SECAPIError):
                raise
            raise SECAPIError(f"Failed to lookup CIK for ticker '{ticker}': {str(e)}")
    
    def _parse_filing_date(self, date_str: str) -> date:
        """
        Parse SEC filing date string to date object.
        
        Args:
            date_str: Date string from SEC API (YYYY-MM-DD)
            
        Returns:
            date: Parsed date object
        """
        try:
            return datetime.strptime(date_str, "%Y-%m-%d").date()
        except ValueError:
            raise SECAPIError(f"Invalid date format from SEC API: {date_str}")
    
    def _determine_file_format(self, file_url: str, form_type: str) -> FileFormat:
        """
        Determine file format from URL and form type.
        
        Args:
            file_url: URL to the filing file
            form_type: SEC form type (10-K, 10-Q, etc.)
            
        Returns:
            FileFormat: Detected file format
        """
        url_lower = file_url.lower()
        
        if url_lower.endswith('.htm') or url_lower.endswith('.html'):
            # Check if it's iXBRL (inline XBRL)
            if 'ix?doc=' in url_lower or '_htm.xml' in url_lower:
                return FileFormat.IXBRL
            return FileFormat.HTML
        elif url_lower.endswith('.txt'):
            return FileFormat.TXT
        elif url_lower.endswith('.xml') or 'xbrl' in url_lower:
            return FileFormat.IXBRL
        else:
            # Default to HTML for most SEC filings
            return FileFormat.HTML
    
    def _extract_fiscal_period(self, filing_data: Dict[str, Any]) -> Optional[str]:
        """
        Extract fiscal period from filing data.
        
        Args:
            filing_data: Filing information from SEC API
            
        Returns:
            str: Fiscal period (Q1 2023, FY 2023, etc.) or None
        """
        try:
            # Try to get period from filing data
            period_of_report = filing_data.get('periodOfReport')
            form_type = filing_data.get('form', '').upper()
            
            if not period_of_report:
                return None
            
            # Parse the period date
            period_date = datetime.strptime(period_of_report, "%Y-%m-%d")
            year = period_date.year
            
            # Determine quarter/period based on form type and date
            if form_type in ['10-K', '10-K/A']:
                return f"FY {year}"
            elif form_type in ['10-Q', '10-Q/A']:
                # Determine quarter from month
                month = period_date.month
                if month in [1, 2, 3]:
                    quarter = "Q1"
                elif month in [4, 5, 6]:
                    quarter = "Q2"
                elif month in [7, 8, 9]:
                    quarter = "Q3"
                else:
                    quarter = "Q4"
                return f"{quarter} {year}"
            else:
                return f"FY {year}"
                
        except (ValueError, KeyError, TypeError):
            logger.warning(f"Could not extract fiscal period from filing data")
            return None
    
    @log_performance("sec_company_lookup")
    def get_company_filings(
        self,
        ticker: str,
        form_types: List[str] = None,
        limit: int = 10
    ) -> List[SECFilingInfo]:
        """
        Get recent filings for a company by ticker symbol.
        
        Args:
            ticker: Company ticker symbol
            form_types: List of form types to retrieve (default: ['10-K', '10-Q', '8-K'])
            limit: Maximum number of filings to return
            
        Returns:
            list: List of SECFilingInfo objects
            
        Raises:
            SECAPIError: If lookup fails
        """
        if form_types is None:
            form_types = ['10-K', '10-Q', '8-K']
        
        try:
            ticker = self._normalize_ticker(ticker)
            logger.info(f"Looking up filings for ticker: {ticker}")
            
            # Get CIK from ticker
            cik = self._get_cik_from_ticker(ticker)
            logger.debug(f"Found CIK {cik} for ticker {ticker}")
            
            # Get company facts (includes recent filings)
            url = f"{self.base_url}/api/xbrl/companyfacts/CIK{cik}.json"
            response = self._make_sec_request(url)
            company_facts = response.json()
            
            # Get submissions data for more detailed filing information
            submissions_url = f"{self.base_url}/submissions/CIK{cik}.json"
            submissions_response = self._make_sec_request(submissions_url)
            submissions_data = submissions_response.json()
            
            # Extract recent filings
            filings = []
            recent_filings = submissions_data.get('filings', {}).get('recent', {})
            
            if not recent_filings:
                logger.warning(f"No recent filings found for {ticker}")
                return []
            
            # Process filings
            forms = recent_filings.get('form', [])
            filing_dates = recent_filings.get('filingDate', [])
            accession_numbers = recent_filings.get('accessionNumber', [])
            primary_documents = recent_filings.get('primaryDocument', [])
            
            for i, form_type in enumerate(forms):
                if len(filings) >= limit:
                    break
                
                if form_type in form_types and i < len(filing_dates) and i < len(accession_numbers):
                    try:
                        filing_date = filing_dates[i]
                        accession_number = accession_numbers[i].replace('-', '')
                        
                        # Construct document URL
                        primary_doc = primary_documents[i] if i < len(primary_documents) else ''
                        doc_url = f"{self.edgar_url}/Archives/edgar/data/{int(cik)}/{accession_number}/{primary_doc}"
                        
                        # Create filing info
                        filing_info = SECFilingInfo(
                            accession_number=accession_numbers[i],
                            filing_date=filing_date,
                            report_type=form_type,
                            report_url=doc_url,
                            file_format=self._determine_file_format(doc_url, form_type).value,
                            fiscal_period=None  # Will be filled when downloading
                        )
                        
                        filings.append(filing_info)
                        
                    except (IndexError, ValueError, TypeError) as e:
                        logger.warning(f"Skipping malformed filing data at index {i}: {e}")
                        continue
            
            logger.info(f"Found {len(filings)} recent filings for {ticker}")
            return filings
            
        except Exception as e:
            if isinstance(e, SECAPIError):
                raise
            raise SECAPIError(f"Failed to get company filings for {ticker}: {str(e)}")
    
    @log_performance("sec_file_download")
    def download_filing(
        self,
        filing_info: SECFilingInfo,
        company_id: str
    ) -> FinancialReport:
        """
        Download a specific filing and create FinancialReport record.
        
        Args:
            filing_info: SEC filing information
            company_id: UUID of company in database
            
        Returns:
            FinancialReport: Created model instance
            
        Raises:
            SECAPIError: If download fails
            FileProcessingError: If file processing fails
        """
        try:
            logger.info(f"Downloading filing: {filing_info.accession_number}")
            
            # Download the file
            response = self._make_sec_request(filing_info.report_url)
            
            # Generate filename
            filename = f"{filing_info.accession_number}_{filing_info.report_type}.html"
            file_path = self.upload_dir / filename
            
            # Save file to disk
            with open(file_path, 'wb') as f:
                f.write(response.content)
            
            file_size = len(response.content)
            logger.info(f"Downloaded {file_size} bytes to {file_path}")
            
            # Validate file size
            max_size_mb = 50
            if file_size > max_size_mb * 1024 * 1024:
                raise FileProcessingError(f"File size {file_size} exceeds {max_size_mb}MB limit")
            
            # Determine report type enum
            try:
                report_type_enum = ReportType(filing_info.report_type)
            except ValueError:
                report_type_enum = ReportType.OTHER
            
            # Determine file format enum
            try:
                file_format_enum = FileFormat(filing_info.file_format)
            except ValueError:
                file_format_enum = FileFormat.HTML
            
            # Create FinancialReport model
            financial_report = FinancialReport(
                company_id=company_id,
                report_type=report_type_enum,
                fiscal_period=filing_info.fiscal_period,
                filing_date=self._parse_filing_date(filing_info.filing_date),
                report_url=filing_info.report_url,
                file_path=str(file_path),
                file_format=file_format_enum,
                file_size_bytes=file_size,
                download_source=DownloadSource.SEC_AUTO,
                processing_status=ProcessingStatus.PENDING
            )
            
            logger.info(f"Created FinancialReport record for {filing_info.accession_number}")
            return financial_report
            
        except Exception as e:
            if isinstance(e, (SECAPIError, FileProcessingError)):
                raise
            raise SECAPIError(f"Failed to download filing {filing_info.accession_number}: {str(e)}")
    
    def get_latest_filing(
        self,
        ticker: str,
        form_type: str = "10-K"
    ) -> Optional[SECFilingInfo]:
        """
        Get the most recent filing of a specific type for a company.
        
        Args:
            ticker: Company ticker symbol
            form_type: SEC form type (10-K, 10-Q, 8-K)
            
        Returns:
            SECFilingInfo: Latest filing info or None if not found
        """
        try:
            filings = self.get_company_filings(ticker, [form_type], limit=1)
            return filings[0] if filings else None
        except SECAPIError as e:
            logger.error(f"Failed to get latest {form_type} for {ticker}: {e}")
            return None
    
    def download_latest_report(
        self,
        ticker: str,
        company_id: str,
        form_type: str = "10-K"
    ) -> Optional[FinancialReport]:
        """
        Download the latest report of a specific type for a company.
        
        Args:
            ticker: Company ticker symbol
            company_id: UUID of company in database
            form_type: SEC form type to download
            
        Returns:
            FinancialReport: Downloaded report or None if not available
        """
        try:
            filing_info = self.get_latest_filing(ticker, form_type)
            
            if not filing_info:
                logger.warning(f"No {form_type} filings found for {ticker}")
                return None
            
            return self.download_filing(filing_info, company_id)
            
        except (SECAPIError, FileProcessingError) as e:
            logger.error(f"Failed to download latest {form_type} for {ticker}: {e}")
            return None
    
    def search_filings_by_date_range(
        self,
        ticker: str,
        start_date: date,
        end_date: date,
        form_types: List[str] = None
    ) -> List[SECFilingInfo]:
        """
        Search for filings within a specific date range.
        
        Args:
            ticker: Company ticker symbol
            start_date: Start date for search
            end_date: End date for search
            form_types: List of form types to include
            
        Returns:
            list: Filtered list of filings in date range
        """
        try:
            all_filings = self.get_company_filings(ticker, form_types, limit=100)
            
            # Filter by date range
            filtered_filings = []
            for filing in all_filings:
                filing_date = self._parse_filing_date(filing.filing_date)
                if start_date <= filing_date <= end_date:
                    filtered_filings.append(filing)
            
            return filtered_filings
            
        except SECAPIError as e:
            logger.error(f"Failed to search filings by date range for {ticker}: {e}")
            return []
    
    def health_check(self) -> Dict[str, Any]:
        """
        Perform a health check of SEC API connectivity.
        
        Returns:
            dict: Health status information
        """
        try:
            # Test basic connectivity with company tickers endpoint
            url = f"{self.base_url}/files/company_tickers.json"
            
            start_time = time.time()
            response = self._make_sec_request(url)
            response_time = time.time() - start_time
            
            # Verify response contains expected data
            data = response.json()
            
            return {
                'status': 'healthy',
                'base_url': self.base_url,
                'response_time_seconds': round(response_time, 2),
                'rate_limit': self.rate_limit,
                'user_agent': self.user_agent,
                'companies_available': len(data) if isinstance(data, dict) else 0,
                'test_completed': True
            }
            
        except Exception as e:
            return {
                'status': 'unhealthy',
                'base_url': self.base_url,
                'error': str(e),
                'rate_limit': self.rate_limit,
                'user_agent': self.user_agent,
                'test_completed': False
            }
